<?xml version="1.0" ?>
<sec_map>
	<section>
		<chunk>HornSchunck optical flow applied to deformation measurement of a birdlike airfoil Gong Xiaoliang a, * , Stephan Bansmer b a School of Aeronautics, Northwestern Polytechnical University, Xian 710072, China b Institute of Fluid Mechanics, Technische Universita t Braunschweig, Braunschweig 38108, Germany Received 16 October 2014; revised 20 April 2015; accepted 11 May 2015 Available online 2 September 2015 KEYWORDS Deformation measurements; Flexible airfoil; HornSchunck; Optical flow; Stereoscopic Abstract Current deformation measurement techniques suffer from limited spatial resolution. In this work, a highly accurate and high-resolution HornSchunck optical flow method is developed and then applied to measuring the static deformation of a birdlike flexible airfoil at a series of angles of attack at Reynolds number 100,000 in a low speed, low noise wind tunnel. To allow relatively large displacements, a nonlinear HornSchunck model and a coarse-to-fine warping process are adopted. To preserve optical flow discontinuities, a nonquadratic penalization function, a multi- cue driven bilateral filtering and a principle component analysis of local image patterns are used. First, the accuracy and convergence of this HornSchunck technique are verified on a benchmark. Then, the maximum displacement that can be reliably calculated by this technique is studied on synthetic images. Both studies are compared with the performance of a LucasKanade optical flow method. Finally, the HornSchunck technique is used to estimate the 3-D deformation of the birdlike airfoil through a stereoscopic camera setup. The results are compared with those computed by LucasKanade optical flow, image correlation and numerical simulation. O 2015 The Authors. Production and hosting by Elsevier Ltd. on behalf of CSAA &amp; BUAA. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). </chunk>
	</section>
	<section>
		<heading>1. Introduction </heading>
		<chunk>For the past few decades, many questions about natural flying mechanisms found in birds and insects remain open even though there has been continuous and substantial research in the matter through theoretical, experimental and numerical results in flapping flight. One example is how aerodynamic forces, elastic forces and inertial forces interact with each other during different flapping phases (e.g., plunging and pitching) when the wings deform significantly. To reveal the hidden mechanism behind this aeroelastic interaction, the deformation of the flexible wing should be measured as precisely as possible. The history of optical measurements of the deformation of the wing of an aircraft model in the wind tunnel can be dated back to the 1970s when photogrammetry 1 was first introduced and evaluated. The dynamic counterpart of photogrammetry is videogrammetry which is applied to a series of images taken sequentially at high rate, providing a proper means of studying the motion of the object as a function of time. 2 Accurate pho- togrammetry requires high contrast surface features on the * Corresponding author. Tel.: +86 29 88494356. E-mail address: xlianggong@gmail.com (X. Gong). Peer review under responsibility of Editorial Committee of CJA. Production and hosting by Elsevier Chinese Journal of Aeronautics, (2015), 28(5): 13051315 Chinese Society of Aeronautics and Astronautics &amp; Beihang University Chinese Journal of Aeronautics cja@buaa.edu.cn www.sciencedirect.com http://dx.doi.org/10.1016/j.cja.2015.07.005 1000-9361 O 2015 The Authors. Production and hosting by Elsevier Ltd. on behalf of CSAA &amp; BUAA. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). measured object. Normally, painted-on targets 3 or retro- reflective tape targets 4 are placed at the locations where the deformation data is required. In situations where there are restrictions on those attached physical targets, the natural identifiable patterns on the wings 5 or projected patterns 6 serve as alternative choices. The primary disadvantage of pho- togrammetry is the lack of deformation data over the entire captured surface, leading to the use of deformation data at sparse points and accordingly interpolated data. 7 Another widely used method is moire  and fringe projection interferom- etry (MFPI) that was initially introduced in 1995 by German Aerospace Research Center DLR in the transonic wind tunnel Go  ttingen to quantitatively measure the bending and twist deformations of the wing. 8 MFPI uses the projection of a fringe pattern or grating to measure the topology of a given surface. Although less accurate than photogrammetry, MFPI reveals the full-field object shape and deformation. The main drawback of MFPI is that despite the ability to measure the out-of-plane model shape and deformation, it encounters a huge challenge when tracking the in-plane motion. 9 The third method is image correlation. The underlying principle is to track the motion of the random speckling patterns on the sur- face by analyzing the displacement of the patterns within dis- cretized subsets (interrogation windows). The displacement in each window can be found by maximizing a correlation func- tion. 10 Image correlation has only recently become increasingly popular. 11 It has been proved to be much more robust and provides greater dynamic range than many other full-field imaging techniques such as MFPI, 12 and has competitively high accuracy compared to traditional strain gages, 13 laser dis- placement sensors, 14 and target-based photogrammetry. 15 In spite of all this, image correlation has drawbacks. The main one is that the spatial resolution is confined by the interroga- tion window size. The task of this paper is to explore a power- ful method that possesses higher spatial resolution than image correlation while preserving the high accuracy. Optical flow is very likely to challenge image correlation in this case. Optical flow calculates the velocity field of pattern motions in 2-D images. It is an effective technique to track the motion of an object. For example, optical flow has been used to detect human movements, navigate vehicles, and measure surface strain, plant growth, and flow motion. Nevertheless, optical flow has rarely been applied to measuring the deformation of aircraft or wings in wind tunnels. The main reason lies in the fact that those mentioned techniques are well developed and perform well. Actually, there is a close relationship between optical flow and image correlation. According to the categorization of dif- ferent optical flow methods by Barron et al., 16 the Horn Schunck (HS) optical flow is a differential technique that has higher spatial resolution, while the image correlation is a region-based matching method that is more robust against noise. Optical flow is usually classified into two categories: glo- bal methods based on the HS scheme 17 and local methods based on the LucasKanade (LK) scheme. 18 Both methods are based on the same assumption that the pixel value (image intensity or brightness) of moving patterns does not change over a short displacement. This is known as the intensity con- stancy assumption. To calculate the velocity field of moving patterns, apart from this assumption, more constraints are required. HS scheme assumes that the velocity field varies globally smoothly and neighboring pixels have almost the same velocity, while LK scheme assumes that the velocity field keeps locally constant and neighboring pixels in one interroga- tion window share the same motion. As a result, HS generates a dense velocity field and it is sensitive to outliers and noise, while LK generates a relatively sparser velocity field but it offers high robustness under outliers and noise. 19 Recently, LK optical flow method has been applied to the static defor- mation measurements of a birdlike airfoil in a wind tunnel experiment by Gong et al. 20 The results of LK clearly manifest higher spatial resolution than those of image correlation and displayed high accuracy at the same time. In this paper, we intend to expand their work and study the possibility of HS optical flow method to measure the deformation of a birdlike airfoil. </chunk>
	</section>
	<section>
		<heading>2. HornSchunck optical flow </heading>
		<chunk>Since Horn and Schunck proposed their famous method in 1981 17 , many researches have been trying to overcome the drawbacks of this method and improve its robustness and accuracy, which is clearly demonstrated by the results on the Middlebury optical flow benchmark. 21 In the rest of this sec- tion, first, the original HS method will be briefly discussed. Then, specific techniques to improve the original method will be introduced. Let I 1 X; Y; t denote the two-dimensional image intensity, where X and Y describe the location of a pixel in image coor- dinates and t is the time. Let I 2 X dX; Y dY; t dt denote the pixel intensity after a short time duration dt, where dX, dY are the displacements of this pixel in the image. The fundamen- tal assumption of optical flow is that the intensity of a pixel is not changed by the displacement. This intensity constancy could be described mathematically as follows: I 1 X; Y; t 14 I 2 X dX; Y dY; t dt 1 By performing a first-order Taylor expansion on I 2 , with velocity U 14 dX=dt, V 14 dY=dt, and denoting partial deriva- tives of the image intensity as I X ; I Y ; I t , we have the linearized version of intensity constancy assumption: I X U I Y V I t 14 0 2 Eq. (2) is the famous optical flow equation. 17 Since U and V are two unknowns, this equation system is underdetermined, which is also the well-known aperture problem. To solve this problem, first, HS adds a global constraint that penalizes the global deviation from the intensity constancy assumption, which is defined by the following energy functional: E D U; V 14 Z X uI X U I Y V I t 2 dX 3 Second, HS adds an extra global constraint that penalizes the total variation of the flow field, which is defined by the fol- lowing energy functional: E S U; V 14 Z X uU 2 X uU 2 Y uV 2 X uV 2 Y dX 4 where E D is commonly called the data term, E S is commonly called the smoothness term. The smoothness constraint is expressed in the gradient of the optical flow velocity, which is reasonable because the velocities of neighboring pixels vary smoothly except at the boundaries of objects in the scene. 1306 X. Gong, S. Bansmer Here, u is the penalty function and O the image spatial domain. In the original HS method, the authors used the quad- ratic penalty us 2 14 s 2 . Assembling the data term from Eq. (3) and smoothness term from Eq. (4) yields the total energy func- tional E: EU; V 14 E D bE S 5 Here, b is a weighting factor (b &gt; 0). Applying a proper minimization method on EU; V, the flow field can be retrieved. </chunk>
	</section>
	<section>
		<heading>2.1. Improvements of original HS model </heading>
		<chunk>As proved by many later researchers, there are mainly three drawbacks of the original HS model. First, the linearization of Eq. (1) maintains accurate only for quite small displace- ments. This issue was first addressed by Nagel 22 and a new nonlinear data term was introduced as follows: E D U;V 14 Z X uI 2 X dX;Y dY;t dt AI 1 X;Y;t 2 dX 6 This new nonlinear data term was later proved capable of capturing larger displacements with higher accuracy and it remains most widely used. This paper uses this new data term from Eq. (6) together with aforementioned smoothness term in Eq. (4) to form the total energy functional shown in Eq. (5). The second drawback of the original HS model lies in the quadratic penalty. As discussed by Black and Anandan, 23 the quadratic estimator is susceptible to outliers, which is one important reason for the erroneous estimation of the opti- cal flow across motion boundaries, thus leading to an over- smooth boundary. In contrast, the L 1 norm, us 2 14 jsj, allows to preserve sharp discontinuities. The integral of the L 1 norm is referred to as the total variation. The successful applications of the L 1 norm in optical flow have been demonstrated by many researchers. 24,25 In this paper, a differentiable approxi- mation of the L 1 norm us 2 14 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi s 2 2 2 p was used. The param- eter 2 is a small constant only for numerical reasons. We set 2 = 0.001, the same as that by Brox et al. 24 The third defect of the original HS model is that because the smoothness term is applied indiscriminately across the whole image, even with the introduction of the discontinuity- preserving L 1 norm, the resulting flow field often shows over-smoothing across motion boundaries. To solve this prob- lem, inspired by the work of Brox and Weickert, 26 a flow- driven or image-driven anisotropic diffusion tensor (smooth- ing data along a boundary rather than across it) could be used to replace the smoothness term (homogenous smoothing). In this case, as demonstrated by Xiao et al., 27 the minimization of the total energy could be separated into a two-step proce- dure: (A) calculating an intermediate optical flow field ~ V; (B) applying an independent diffusion on the intermediate flow field. Then, the anisotropic diffusion can be substituted by a more flexible oriented Gaussian filter that does not need tradi- tional PDE iteration anymore. At occluded regions, when per- forming the oriented Gaussian filter only within the region where the kernel central pixel is therein, the resulting flow field is more accurate than that of the traditional anisotropic diffu- sion that unavoidably takes in some flow information from inconsistent regions despite the smoothing (diffusion) being stretched along the motion boundary. 27 Because different Gaussian filters can be simply concatenated by convolution operation, it is much more straightforward to include Gaus- sian filters representing spatial distance, image similarity, and motion similarity into one filter W: 27 W 14 RG X X; r X G I I; r I G~ V ~ V; r~ V 7 where R denotes the occlusion labeling, G </chunk>
	</section>
	<section>
		<heading>X X; r </heading>
		<chunk>X a Gaussian kernel on image spatial domain X with variance r X , G I I; r I a Gaussian kernel on image intensity domain I with variance r I , and G~ V ~ V; r~ V a Gaussian kernel on intermediate flow velocity domain ~ V with variance r~ V . The occlusion labeling R calcu- lated by Xiao et al. 27 is based on checking the squared image intensity difference between two sequential images, which is not reliable because the motion boundary and image intensity boundary may not coincide. In this paper, R is calculated according to the flow-divergence-difference-based method. 28 Finally, if we convolute ~ V by W, the desired flow field can be generated by this weighted average filtering. 27,28 However, a better approach is to apply a weighted median filter that inherits edge preservation and efficient noise attenuation of the median filter. 29 Median filtering of intermediate flow fields has been proved to be very effective to improve accuracy. This paper carries out a fast version of weighted median filtering proposed by Sun et al. 30 </chunk>
	</section>
	<section>
		<heading>2.2. Improvements of minimizations of original HS </heading>
		<chunk>Apart from some defects in the model, the old minimization method is also responsible for inaccurate results of original HS. In this paper, the minimization of total energy EU; V was carried out according to the famous warping-based method proposed by Brox et al. 24 The main contribution of his method is to postpone the linearization to the numerical scheme. The original HS estimated spatial derivatives of image intensity by first-order difference which is obviously not accu- rate enough. This paper took a five-point central difference stencil 1/12[A1, 8, 0, A8, 1] that was suggested by Barron et al. 16 Like original HS, the final spatial derivatives were calculated by the temporal average of spatial derivatives of two sequential images. The only difference is that in this paper the spatial derivatives on the second image were estimated on the warped image that was generated during the coarse-to-fine warping process. This process consists of the optical flow calculation on pyramidal images and the cubic-interpolation- based warping, which has been generally recognized as a high performance technique, especially for large displacements. 24 Pyramidal images were multi-scale images which were acquired by continuously calculating Gaussian pyramid reduction of the full resolution image. The reduction factor was 0.5. The number of pyramid levels was adaptively determined so that each dimension of the coarsest image was around 30 pixels. 31 Computations started from the coarsest image, and then went to the next finer image, until finally solved the optical flow of the full resolution image. At each pyramidal level, an inner warping iteration was performed to refine the optical flow. It is well-known that the flow fields at textureless regions (the data term vanishes) are generated by the fill-in process induced by the smoothness term. If the textureless region is surrounded by the similar-motion-belonged textured region, HornSchunck optical flow applied to deformation measurement of a birdlike airfoil 1307 this fill-in process helps to generate a full density optical flow field. Otherwise, an erroneous flow field at the textureless region may be induced. In the experiments of this paper, because the textured object moved on a static textureless back- ground, the textureless region could be easily identified by measuring the smaller eigenvalue of the local image intensity structure tensor. As Gong et al. did in their work, 20 if the smal- ler eigenvalue was less than 1, the velocity was set to zero. </chunk>
	</section>
	<section>
		<heading>3. Validation of HS optical flow </heading>
	</section>
	<section>
		<heading>3.1. LK optical flow </heading>
		<chunk>To validate the HS optical flow code, both accuracy and con- vergency of HS optical flow results were studied in comparison with LK optical flow studied by Gong et al. 20 LK optical flow minimizes the sum of the squared error between I 1 X; Y; t and I 2 X dX; Y dY; t dt in an integration window w. After linearization is done in Eq. (2), a total energy is generated: EU; V 14 X X;Y2w I x U I y V I t 2 8 The minimization of E in Eq. (8) leads to a linear system where U and V can be resolved. The LK used by Gong et al. also took advantage of coarse-to-fine warping and pyramidal scheme. Apart from that, nonlinear structure tensor diffusion was used to preserve motion discontinuity. </chunk>
	</section>
	<section>
		<heading>3.2. Spinning sphere </heading>
		<chunk>To compare the results of HS to the results of LK, the valida- tion here was carried out on the same two image sequences used for LK. The first one is the synthetic sphere sequence. 32 A textured sphere is spinning in a static striped background, see Fig. 1(a). All color images were converted into grayscale images, because black and white photos were used in experi- ments. The three parameters of bilateral filtering were set according to experience to be: r X 14 7, r I 14 3, r~ V 14 4. The inner iteration step for warping was 20. The result is shown by the color coded map in Fig. 1(d). The velocity orientation and magnitude are represented by the hue and brightness in the color wheel shown in Fig. 1(b), respectively. Obviously, the HS optical flow result preserved a much sharper motion discontinuity than the LK optical flow result (see Fig. 1(f)). When comparing sphere optical flow with true flow (see Fig. 1(c), the advantage of HS in preservation of the sphere boundary is even more clear (see Fig. 1(e) and (g)). The error image was measured in endpoint error (EE). EE is calculated by measuring the flow difference between the optical flow V 14 12U; V; 1 and the true flow V t 14 12U t ; V t ; 1. EE 14 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi U A U t 2 V A V t 2 q 9 To further understand this difference quantitatively, a 3-pixel-width annular region was defined on the sphere bound- ary. The average EEs of HS and LK within this annular region were 0.66 pixel and 1.10 pixels, respectively while the average EE of HS and LK within the sphere were equally 0.1 pixel. The above discussion seems to convince that the HS, com- pared to LK, achieved the same performance in non-occlusion region (within the sphere). However, examining the optical flow result carefully reveals the fact that the optical flow of HS (see Fig. 1(d)) retrieved a more clear longitude line than that of LK (see Fig. 1(f)). This difference cannot be illustrated by the average EE, which will be discovered by some other error measurements. Generally, apart from EE, two other ways to validate the optical flow results are the average angular error (AE) and the standard deviation of angular error (SDAE). AE measures the angular difference between the optical flow V and the true flow V t . AE 14 arccos UU t VV t 1 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi U 2 V 2 1 p ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi U 2 t V 2 t 1 q 0 B @ 1 C A 10 Fig. 1 Optical flow of spinning sphere. 1308 X. Gong, S. Bansmer It is noted that large and small velocities were treated with- out amplification for AE. In contrast, errors of larger velocities measured in EE were weighted more. SDAE is defined as the standard deviation of AE. Fig. 2 shows angular error images of HS and LK results which are very similar to their corresponding EE images in Fig. 1. Again, big errors appeared on the sphere boundary and HS preserved the boundary better than LK. The average AEs were 23.1 and 35.6 for HS and LK on the sphere bound- ary, respectively, but equally 2.6 within the sphere. The convergence property of HS was compared with that of LK through all three measurements, as shown in Fig. 3. As mentioned before, the EE of HS and LK almost converged to the same level (see Fig. 3(a)). It is the same case with AE (see Fig. 3(b)). However, the flow differences of HS and LK are prominently illustrated by SDAE (see Fig. 3(c)). Therefore, the average errors of both methods were similar while the result of HS showed less variation in the flow direction, which is also indicated in Fig. 2. This clarifies why HS captured sub- tle longitude line in the flow field. </chunk>
	</section>
	<section>
		<heading>3.3. Translating rectangle </heading>
		<chunk>The second synthetic image sequence was obtained in order to know the limit of the motion magnitude for the HS method. In the scene, a rectangle with random pattern is translating towards the right on a static black background (see Fig. 4 (a)). The true flow is shown in Fig. 4(b) by subsampled velocity vectors. To compare with the result of LK 20 , first the HS optical flow method was applied to displacement from 1 pixel to 6 pix- els. All parameters were kept the same as used in the sphere sequence. The EE is shown by a grayscale images in Fig. 5 (a). It is clearly shown in Fig. 5(a) that the effectiveness of HS to preserve flow discontinuity hardly degenerated with the increasing motion displacement from 1 pixel to 6 pixels in great contrast to the obvious deterioration of LK shown in Fig. 5(b). The comparison of EE between HS and LK demonstrates that even when the displacement was 1 pixel, HS optical flow generated a much smaller error than LK opti- cal flow on the motion boundary. The larger the displacement, the greater advantage HS had in preserving the motion boundary. The previous discussion did not answer what the ultimate limit of the motion displacement calculated by HS optical flow is. To study this, the displacement was increased to 7 pixels. The results were still shown in three measurements, EE, AE and SDAE (see Fig. 6). Again, all the three measurements obviously show that HS generated a more accurate flow field than LK. The errors of HS kept at a rather constant low level from 1 pixel to 6 pixels, while the errors of LK increased lin- early from 1 pixel to 3 pixels, showed a jump at 4 pixels, and Fig. 2 Comparison of angular error between HS and LK. Fig. 3 Convergency property measured in three methods. HornSchunck optical flow applied to deformation measurement of a birdlike airfoil 1309 then went up linearly to 6 pixels. Actually, those error curves quantitatively display the variation of grayscale error images shown in Fig. 5, because the biggest errors occurred around the motion boundary in both, HS and LK. Last but not least, errors of both HS and LK increased sharply with the displace- ment increasing from 6 pixels to 7 pixels. Thus, in the follow- ing experiment, as a compromise between motion magnitude and optical flow accuracy, the maximum motion was limited to fewer than 6 pixels, twice the motion limitation of LK. 20 </chunk>
	</section>
	<section>
		<heading>4. Experimental setup </heading>
		<chunk>Wind tunnel experiments of measuring the deformation of the birdlike airfoil were carried out in a low speed, low noise wind tunnel. The airfoil (see Fig. 7) is an advanced version of the flex- ible birdlike airfoil SG04 presented by Bansmer et al. 33 The wings dimensions are 398 A 200 mm (span A chord). The fore part of the wing is stiff and the rear part of the wing is com- posed of seven overlapping flexible feather shells. The white upper surface of the wing was sprayed with stochastic black ink patterns. To measure 3-D deformation of the wing, a stereoscopic camera (1280 A 1024 pixels) system was used (see Fig. 8). The enclosed angle between two camera viewing axes was approximately 90, ensuring optimum measurement accuracy. 10 However, such a camera setup could not make the whole upper surface of the wing within focus for both cam- eras. The out-of-focus images pose a threat to most optical measurements (see Fig. 7). A usual solution to increase the depth of view is to use the Scheimpflug adapter between lens and sensors. 10 A programmable timing unit (PTU) synchro- nized a flash lamp with the two cameras. Deformation measure- ments were repeated when the angle of attack (AoA) a of the airfoil was 0, 2, 4, 6, 8, 10, respectively. For each AoA, the free stream velocity u 1 was gradually increased from 0 to 8 m/s to avoid too large displacements. At each flow condition, the programmable timing unit controlled the synchronization between the flash lamp and cameras. Finally, we got two image series for both cameras for each flow condition. More informa- tion about the experimental setup is in earlier work. 20 </chunk>
	</section>
	<section>
		<heading>5. Experimental results </heading>
	</section>
	<section>
		<heading>5.1. Optical flow for airfoil deformation measurements </heading>
		<chunk>Because the largest pattern displacement due to wing deforma- tion between wind off (0 m/s) and wind on (8 m/s) was greater Fig. 4 Random-pattern-textured translating rectangle. Fig. 5 Endpoint error for motion from 1 to 6 pixels. 1310 X. Gong, S. Bansmer than 6 pixels, the HS optical flow would not yield accurate results as demonstrated before. In consequence, the deforma- tion was determined between 0 m/s to 5 m/s, 5 m/s to 7 m/s, and 7 m/s to 8 m/s. At each data point, the flexible shells of the wing deflected steadily and 30 images were taken. The post processing process of these images was the same as the LK method. 20 A simple average strategy, a histogram stretching and a Gaussian filter were successively applied to recorded images to enhance their quality. Then, for each camera, the optical flow between images of aforementioned neighboring velocities was calculated by HS and added up to get the final optical flow. Finally, each camera generated an optical flow field estimating the airfoil deformation in images between 0 m/s and 8 m/s. It is noted that all the parameters were kept the same as before except that the inner warping iteration was reduced to 3, which demonstrates the more robustness of HS than LK whose parameters have to be tuned carefully for different input images. 20 Two images taken by two cameras when AoA of the airfoil was 8 at wind off are shown in Fig. 9(a1) and Fig. 9(a2). It is worth noting that the airfoil was not homogenously illumi- nated, and that is why a histogram stretching was carried out. For the airfoil at 8, two HS optical flow fields between 0 m/s and 8 m/s for the two corresponding cameras can be seen in Fig. 9(b1) and (b2). As before, the optical flow was coded by the color wheel (see Fig. 1(b)). Not only sharp discontinuities were preserved, but also the gaps between overlapping flexible shells were captured. However, it is interesting to see that LK captured a more noticeable gap, see Fig. 9(c1) and (c2). This can be explained by the image-driven anisotropic diffusion ten- sor used in LK optical flow. Actually, as the air flow ran across the wing almost evenly, the overlapping shells deformed almost the same along the spanwise direction. The deforma- tion difference of the gap and the shell was not so obvious, which can be indicated by the construction of the airfoil (see Fig. 7). As a result, we assume that the HS optical flow in gap regions was more realistic. To illustrate the difference of HS and LK in motion boundary, the enlarged views of Square 1 and Square 3 (the green squares in Fig. 9(a1) and (a2) are shown in Fig. 9(a-3-1) and (a-3-3), respectively. As expected, the optical flow of HS (Fig. 9(b-3-1) and (b-3-3)) preserved an obviously much better velocity discontinuity than that of LK (Fig. 9(c-3-1) and (c-3-3)). At the same time, HS showed higher sensitivity to noise compared to LK (see Fig. 9(b-3-2), (b-3-4), (c-3-2) and (c-3-4)). The square 2 in Fig. 9(a1) repre- sents a low motion displacement region where the noise was dominated by random vibration of the airfoil and none homogenous illumination. Square 4 in Fig. 9(a2) represents a high specular reflection region, which resulted from the alu- minum frame where the noise was dominated by the violation of intensity constancy assumption. The velocity range for images from camera 1 was U 1 2 [A0.66, 2.70] pixels, V 1 2 [A4.47, 1.51] pixels, while the velocity range for images from camera 2 was U 2 2 [A16.31, 1.70] pixels and V 2 2 [A2.78, 2.41] pixels. Fig. 6 Errors with increasing motion magnitude. Fig. 7 Flexible birdlike airfoil. Fig. 8 Stereo camera setup. HornSchunck optical flow applied to deformation measurement of a birdlike airfoil 1311 </chunk>
	</section>
	<section>
		<heading>5.2. Airfoil vertical deformation </heading>
		<chunk>After camera calibration, the 3-D velocity field can be calcu- lated by the stereo optical flow fields. Because the Scheimpflug condition was used in experiments to increase the depth of view, the image plane and the lens plane were not parallel any- more, accordingly, and the polynomial model 34 rather than the pinhole model was used to calibrate cameras. The polynomial had a cubic dependence in x and y, but a quadratic dependence in z. The calibration grid was inclined with the same angle of the chord line of the airfoil and was translated to three z posi- tions with an interval of 10 mm, containing the whole range of airfoil deformation. Once cameras were calibrated, the corre- spondence between a point of the real world and two pixels of two stereo images was recovered. Combining two optical flow fields according to the method proposed by Soloff et al., 34 we could calculate the 3-D displacement of the wing. As the SG04 airfoil during wind on deforms in a 2-D way, the vertical deformation predominates the 3-D displacements. This vertical deformation dz calculated by HS is shown by a contour graph in Fig. 10(a). The result was nondimensional- ized by the chord length c. Compared with the result of LK (see Fig. 10(b)), HS illustrated a smoother flow field in the flex- ible shells (deformed region), which was the actual situation as discussed before. LK captured the gaps between overlapping shells more clearly than HS. However, as mentioned before, the patterns of the flow field of LK in the flexible shells were mostly induced by the image-driven anisotropic diffusion pro- cess where the local texture and local motion was not consis- tent. In the near-zero deformation region, HS showed more fluctuation than LK, which was mainly the result of none homogenous illumination. Again, it is demonstrated that HS was more sensitive to noise than LK. However, it should be remembered that HS generated 100% dense flow filed while LK could not because a Gaussian integration window (22 pix- els) was utilized by LK 20 (see Eq. (8)). The HS result was also compared with the traditional image correlation result (see Fig. 10(c)). Apparently, the image correlation result was much smoother than both optical flow results, which was under expectation because a large interrogation window (from 128 A 128 pixels down to 32 A 32 pixels, with 50% overlap) was used during image correlation calculations. 20 Smaller interrogation windows were tested before calculations, but the results showed that a window size of 32 A 32 pixels Fig. 9 Airfoil images (a = 8, u 1 = 0 m/s) and corresponding optical flow fields (a = 8, u 1 = 08 m/s). 1312 X. Gong, S. Bansmer provided the best compromise between spatial resolution and accuracy. Therefore, image correlation will fail to capture motion details and tend to blur motion boundaries because its resolution is confined by the interrogation window size. A sharp motion boundary of the image correlation result shown in Fig. 10(c) does not result from the image correlation method but from a manually defined polygon mask that fits the outline of the airfoil in images. Finally, the HS result was compared with the numerical simulation result (see Fig. 10(d)). It is noted that the lines in Fig. 10(d) represent finite-element model used in the structural part of the simulation rather than contour lines. The numerical simulation was based on solving the fluidstructural interaction (FSI) problem by a partitioned coupling approach where the fluid and structural solvers are linked together in a well-validated coupling environment with the aid of flexible data transfer libraries. 20 The deformation contour of FSI showed good agreement with that of HS, LK and image correlation. To further show the difference between the results of HS, LK, image correlation and FSI, a slice was cut at y=c = A0.0825 of three experimental results in Fig. 10 along the chord line, while a slice was cut at the horizontal midline of the FSI result. The vertical deformation curves of different methods are shown in Fig. 11(a). All these curves are consis- tent with each other. The deformation of the wing starts around 0.38c from the leading edge, displays an exponential- like increase and reaches the peak value around 0.018c. Three experimental curves show small oscillation only when dz=c was close to zero. Again, the HS result showed the biggest fluctua- tion in the near-zero deformation region. The advantage of HS over LK in motion-discontinuity preservation can still be seen around x=c = 1 in Fig. 11(a), where the deformation curve of HS dropped down more sharply than the curve of LK. How- ever, this advantage is not so obvious because of the small scale of this motion-blur region compared to the image size. From another perspective, this also proves the applicability of LK optical flow in this experiment, despite the not so over- whelming power in preserving the motion boundary, com- pared to HS. Finally, HS method was applied to images of the whole ser- ies of AoA. HS optical flow fields and the corresponding 3-D vertical deformation contours were calculated, respectively. Then, the trailing edge deflections for each AoA were recov- ered. The deflections calculated by HS were illustrated in Fig. 11(b), together with the results of LK and FSI. The results of HS and LK show a perfect match, which demonstrates that both of HS and LK are capable of capturing large deformation of the wing accurately. Both optical flow results are in good agreement with FSI results except for the strayed value at 0, where the numerical simulation overestimates the experimental Fig. 10 Vertical deformation of different methods (a = 8, u 1 = 08 m/s). HornSchunck optical flow applied to deformation measurement of a birdlike airfoil 1313 value. A reasonable linear correlation between the trailing edge deflection and angle of attack can be demonstrated in Fig. 11 (b). </chunk>
	</section>
	<section>
		<heading>6. Conclusions </heading>
	</section>
</sec_map>

